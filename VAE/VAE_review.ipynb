{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **확률 모델 목적**:\n",
    "   - 확률 모델링 관점에서, 데이터 $x$가 주어졌을 때, 이 데이터를 생성할 수 있는 확률 분포 $p_\\theta(x)$를 최대화하려고 합니다. \n",
    "   - 이 확률 분포는 파라미터 $\\theta$에 의해 결정됩니다. \n",
    "   - VAE는 일반적으로 가우시안 분포 $N(z|\\mu, \\sigma)$를 사용하여 이를 모델링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (7).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **잠재 변수의 주변 확률 분포**\n",
    "   - latent variable $z$에 대한 주변 확률 분포(Marginal Probability Distribution) $p_\\theta(x)$는 latent variable $z$에 대해 적분함으로써 얻어집니다.\n",
    "   - 이는 다음과 같은 수식으로 표현됩니다: $p_\\theta(x) = \\int p_\\theta(x, z) dz$. \n",
    "   - 여기서 $p_\\theta(x, z)$는 관측 가능한 데이터 $x$와 그 잠재 표현 $z$에 대한 결합 확률 분포(joint probability distribution)입니다.\n",
    "\n",
    "2. **결합 분포와 조건부 확률**:\n",
    "   - 연쇄 법칙(chain rule)에 따라, 결합 확률 분포는 $p_\\theta(x, z)$를 $p_\\theta(z)p_\\theta(x|z)$로 분해할 수 있습니다. \n",
    "   - $p_\\theta(x|z)$는 latent variable $z$가 주어졌을 때 데이터 $x$의 조건부 확률을 나타냅니다.\n",
    "\n",
    "3. **변분 추론**:\n",
    "   - $p_\\theta(x|z)$의 계산은 대부분의 경우에 계산하기 어렵고 실현 불가능합니다. \n",
    "   - 이를 극복하기 위해, 사후 분포 $p_\\theta(z|x)$를 근사하는 변분 분포 $q_\\phi(z|x)$를 도입합니다. \n",
    "   - 이 근사 분포는 $q_\\phi(z|x) \\approx p_\\theta(z|x)$의 관계를 가집니다.\n",
    "\n",
    "4. **인코더와 디코더**:\n",
    "   - 변분 추론을 사용하여, encoder는 $q_\\phi(z|x)$를 사용하여 latent variable $z$의 분포를 근사합니다. \n",
    "   - decoder는 이 latent variable를 사용하여 데이터 $x$의 조건부 확률 분포 $p_\\theta(x|z)$를 모델링합니다.\n",
    "   - encoder는 $E_\\phi$로, decoder는 $D_\\theta$로 표현됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (8).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 왼쪽 그래프: 가우시안 분포에서 샘플링된 잠재 변수 $z$의 예시입니다.\n",
    "- 오른쪽 그래프: 같은 잠재 변수 $z$를 함수 $g(z)$를 통해 변환하여 생성된 데이터 포인트의 분포를 보여줍니다. \n",
    "  - 여기서 $g(z)$는 $z$에서 데이터 $X$를 생성하기 위해 학습된 결정적 함수입니다. \n",
    "  - 이 경우, 잠재 변수 $z$가 링 형태의 분포를 갖도록 변환된 것을 볼 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "Q. latent space(manifold)가 굉장히 복잡한데 정규 분포에서 샘플링한다고 잘 설명할 수 있나?  \n",
    "A. 우리가 학습할 latent space가 복잡하더라도, 모델이 딥뉴럴넷이기 때문에 generator layer에서 처음 몇 개의 layer는 latent space를 잘 찾기 위한 역할을 수행할 수 있다. 그리고 나머지 레이어들을 통해 latent vector에 맞는 이미지를 생성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (9).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 샘플 여러개 모아서 몬테카를로 방식으로 더하면 PDE 할 수 있지 않나?  \n",
    "A. generator에 대한 확률 모델을 가우시안으로 할 경우, MSE 관점에서 가까운 것이 더 p(x)에 기여하는 바가 크다. 이로인해 의미적으로 맞지 않는 케이스가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (10).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 $z$를 정규 분포에서 샘플링하는 것 보다, $x$와 유의미하게 유사한 샘플이 나올 수 있는 확률 분포 $p(z|x)$로 부터 샘플링하면 된다.   \n",
    "우리는 $p(z|x)$가 무엇인지 알지 못하므로, 우리가 알고 있는 확률 분포 중 하나를 택한 후, $q_\\phi(z|x)$의 파라미터 값을 조정하여 $p(z|x)$와 유사하게 만든다. Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (11).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방법1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (12).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KL 발산은 두 확률 분포 간의 거리 느낌이다. \n",
    "- $p(z|x)$를 모르기 때문에 KL을 최소화하지 못한다. \n",
    "- 따라서 ELBO를 최대화하는 $\\phi$를 찾는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (13).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (14).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (15).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (16).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 손실 함수\n",
    "\n",
    "VAE의 학습은 잠재 변수 $z$의 근사 분포 $q_\\phi(z|x)$와 실제 데이터 $x$의 조건부 분포 $p_\\theta(x|z)$를 최적화하여 이루어집니다.  \n",
    "이 과정에서 두 가지 주요 손실이 고려됩니다:\n",
    "\n",
    "- **재구성 손실**: 데이터 $x$와 재구성된 데이터 $x'$ 사이의 차이를 최소화합니다.\n",
    "- **KL 발산**: 잠재 변수의 근사 분포 $q_\\phi(z|x)$와 사전 분포 $p(z)$ 사이의 차이를 측정합니다.\n",
    "\n",
    "이러한 손실을 결합하여, VAE는 데이터의 생성 과정을 더 잘 모델링할 수 있도록 잠재 공간을 최적화합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (17).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (18).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (19).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (20).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (21).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (22).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (23).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (24).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (25).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/fned49/blog/blob/main/VAE/figure/Variational AutoEncoder (26).png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
